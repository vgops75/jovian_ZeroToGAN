{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 - All about *torch.Tensor*\n",
    "\n",
    "### Deep Learning with PyTorch: Zero to GANs\n",
    "\n",
    "PyTorch is a popular deep learning framework developed and open-sourced by the Facebook, Inc. The framework is based on Torch library, originally developed by Adam Paszke, Sam Gross, Soumith Chintala, and Gregory Chanan. Parts of PyTorch code is written in Python, and rest of the code is based on C++ and CUDA.\n",
    "\n",
    "At present, the PyTorch is competing with Tensorflow which is the most widely used (also an open-sourced deep learning framework from the Google Inc.) framework among the Deep Learning community users based on the data from github database.\n",
    "\n",
    "PyTorch is introduced as a dynamic framework which means the computations of tensor operations happen side by side with their definitions. Tensorflow was introduced as a static framework meaning all the required computations will be defined first, transformed into tensorflow computational graphs, and then get computed. Recently, Tensorflow also introduced Tensorflow 2, a dynamic framework similar to PyTorch.\n",
    "\n",
    "PyTorch comprises powerful modules such as Autograd (provides auto-differentiation of tensors), Optim (for implementing optimization routines), and NN (for neural network library functions), and as well as provides Multiprocessing library and utility functions (Utils). \n",
    "\n",
    "In this notebook, we shall cover a set of few basic functions to familiarize ourselves with the PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import torch and other required modules\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.0\n",
      "1.5.0\n"
     ]
    }
   ],
   "source": [
    "# Find out which version of Torch we are using\n",
    "print(torch.version.__version__)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class torch.tensor is the core class of the package. In this section, we cover a few functions that operates on Tensors. Below is a sample on how to create a tensor in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = torch.tensor([[[1, 2., 5], [3, 4.0, 1], [-1.0, 2, 0]], [[0, 0, 0], [10, 4, 1], [0, 1, 2]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  2.,  5.],\n",
       "         [ 3.,  4.,  1.],\n",
       "         [-1.,  2.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.],\n",
       "         [10.,  4.,  1.],\n",
       "         [ 0.,  1.,  2.]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 1 - find if the given object is tensor\n",
    "\n",
    "We may encounter different kinds of objects defined to suit specific domain oriented applications, and these could either be stored or used as is, during computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define two objects, a list data type x and a standard normal distributed random tensor y.\n",
    "x = [1, 5, 8.3, 2] # x is a list\n",
    "y = torch.randn(3, 3) # y is random tensor of standard normal distribution\n",
    "z = torch.tensor([[1, 3], [2, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the object is a tensor using is_tensor() operand\n",
    "torch.is_tensor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the object is stored as a tensor object.\n",
    "torch.is_storage(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Check if this object y is a tensor and if it is stored -- using print() to do both in the same cell\n",
    "\n",
    "print(torch.is_tensor(y))\n",
    "print(torch.is_storage(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above examples, we see that the x is a list and not a tensor, and hence yields False for .is_tensor(). Also x is not stored but is readily available for computations.\n",
    "\n",
    "Then we also defined z as a tensor using torch.tensor(). This also yields True for .is_tensor(). But the same gives False for .is_storage() which I could not understand. My understanding is that the tensors defined using torch.tensor() is stored somewhere, and hence .is_storage() should be True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 2 at dim 1 (got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-28787d136593>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example 3 - breaking (to illustrate when it breaks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 2 at dim 1 (got 3)"
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking (to illustrate when it breaks)\n",
    "torch.tensor([[1, 2], [3, 4, 5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors should be of same size / shape, and the above gives error because the length of the rows are not same i.e. column size is different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 2 - torch.stack()\n",
    "\n",
    "Sometimes we encounter situations where we need to join two tensors together, and we may want to join these tensors with a specific intention. This also brings down the storage requirements from storing multiple same sized small tensors into storing one single tensor.\n",
    "\n",
    "Say, we don't want to add them numerically, just stack them side by side, like the playing cards of 4 different suits. We use torch.stack() to stack them all in a new dimension (playing cards tuck box). The new dimension here resembles the tuck box here, and the shape of individual tensors should be same to carry-out the stack operation, i.e. (1, 13) in case of cards, each suit having 13 cards, and 4 suits are the 4 tensors that are being stacked by torch.stack() operation.\n",
    "\n",
    "The other possibility of joining is to stack similar categories together while joining them, i.e. concatenation based on similarities. Like getting 2 decks (2 boxes of 52 cards) and joining them together but keeping the suits separate. This way, we will be getting 4 suits of 2 times 13 = 26 cards. Or 4 tensors, with each of them having a shape of (1, 26). In this case, we use torch.cat() to add them up in a specific dimension.\n",
    "\n",
    "Yet another instance of joining would be to add them numerically, which is done by torch.add()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2903,  0.0726, -1.5728]])\n",
      "\n",
      "\n",
      "tensor([[ 0.0995, -1.4382,  0.3038]])\n"
     ]
    }
   ],
   "source": [
    "# Defining dummy tensors to work with the demo of examples\n",
    "\n",
    "a = torch.randn(1, 3)\n",
    "b = torch.randn(1, 3)\n",
    "\n",
    "# We created two tensors of size / shape (1, 3) using random standard normal distribution.\n",
    "# which means that their mean and std deviations are 0 and 1, respectively, for a and b.\n",
    "\n",
    "print(a)\n",
    "print('\\n')\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2903,  0.0726, -1.5728]],\n",
      "\n",
      "        [[ 0.0995, -1.4382,  0.3038]]])\n",
      "torch.Size([2, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "# Example 1 -- default setting parameter dim=0\n",
    "\n",
    "c = torch.stack([a, b], dim=0)\n",
    "print(c)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, the stacking of (1, 3) tensor with another (1, 3) tensor with dim=0, created the new dimension in the index position 0, and stacked each one in a row, thus giving a new tensor of shape (2, 1, 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2903,  0.0726, -1.5728],\n",
      "         [ 0.0995, -1.4382,  0.3038]]])\n",
      "torch.Size([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Example 2 - dimension parameter dim set to 1\n",
    "\n",
    "d = torch.stack([a, b], dim=1)\n",
    "print(d)\n",
    "print(d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the dim=1, we stacked the above tensors in the original row dimension. To understand this, lets say we have a single gray-scaled image represented as a tensor P, then we cut it into two halves horizontally, upper and lower halves, not necessarily equal in height but each of the halves will have the same width. Now lets say, we want to reproduce original P. We can use the torch.stack() with dim=1. This will add these cut halves again into a single image tensor of original size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 1.],\n",
       "        [1., 0., 1.],\n",
       "        [1., 1., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just a quick-check for torch.add() function\n",
    "\n",
    "a1 = torch.eye(3) # creates an identity matrix of size 3 x 3\n",
    "b1 = torch.ones(3) # creates a ones tensor of size 3 x 3\n",
    "torch.add(b1, -a1) # adds them numerically, note the minus sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [2, 1, 3] at entry 0 and [1, 2, 3] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-ccacb861dcd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example 3 - breaking (to illustrate when torch.stack() breaks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [2, 1, 3] at entry 0 and [1, 2, 3] at entry 1"
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking (to illustrate when torch.stack() breaks)\n",
    "\n",
    "e = torch.stack([c, d], dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stacking operation can be done only on tensors of same sizes. PyTorch offers another function torch.cat() to do the stacking operation in case of tensors of different sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another alternative solution in this case is to either use padding to make the short-comings of small sized tensor to match the size of the largest tensor used in the stacking operation, or unsqueeze() or reshape() functions before performing torch.stack() operation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.2903,  0.0726, -1.5728],\n",
      "          [ 0.0995, -1.4382,  0.3038]]],\n",
      "\n",
      "\n",
      "        [[[-0.2903,  0.0726, -1.5728],\n",
      "          [ 0.0995, -1.4382,  0.3038]]]])\n",
      "torch.Size([2, 1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "f = c.reshape(1, 2, 3)\n",
    "e = torch.stack([f, d], dim=0)\n",
    "print(e)\n",
    "print(e.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 3 - torch.cat()\n",
    "\n",
    "As explained before, in order to join tensors of different sizes (concatenation), PyTorch function torch.cat() is used. The catch point is that the concatenation happens in the dimension that is different, and hence rest of the dimensions should be same.\n",
    "\n",
    "For example, we have a batch containing 3 gray-scaled images i.e. a tensor of shape (3, 32, 32, 1), another batch containing 2 gray-scaled images i.e. a tensor of shape (2, 32, 32, 1). Lets see how torch.cat() can be used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 32, 32, 1])\n"
     ]
    }
   ],
   "source": [
    "# Example 1 - along dim=0 (default)\n",
    "batch1 = torch.randn(3, 32, 32, 1)\n",
    "batch2 = torch.randn(2, 32, 32, 1)\n",
    "\n",
    "add_batches = torch.cat([batch1, batch2], dim=0)\n",
    "print(add_batches.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, we just added two batches of images into a single set. Lets see what happens if we have one set containing images belonging to 3 categories of objects, and another set containing images belonging to 2 categories that are different from the previous set. We wanted to add these sets to create a batch, of size (1, 5, 32, 32, 1) i.e. 1 batch containing 5 categories of objects' gray-scaled 32x32 sized images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 32, 32, 1])\n"
     ]
    }
   ],
   "source": [
    "# Example 2 - dim=1, the use case doesn't make any sense though.\n",
    "\n",
    "set1 = torch.randn(1, 3, 32, 32, 1)\n",
    "set2 = torch.randn(1, 2, 32, 32, 1)\n",
    "\n",
    "# Lets concatenate in the dim=1 dimension\n",
    "batch = torch.cat([set1, set2], dim=1)\n",
    "print(batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above example is only demonstrating the use of torch.cat(). In the real-case scenarios, we don't carry the category information with the images. Either they appear as a target variable or unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 3. Got 100 and 50 in dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a1d674bfad3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mset6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mbatch1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mset3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 3. Got 100 and 50 in dimension 0"
     ]
    }
   ],
   "source": [
    "# Example 3 - Only one dimension can be different i.e. the dimension\n",
    "# where the concatenation happens; rest of the dimensions should be matching.\n",
    "\n",
    "set3 = torch.randn(100, 32, 32, 1)\n",
    "set4 = torch.randn(100, 32, 32, 3)\n",
    "set5 = torch.randn(100, 64, 64, 1)\n",
    "set6 = torch.randn(50, 32, 32, 3)\n",
    "\n",
    "batch1 = torch.cat([set3, set6], dim=3)\n",
    "print(batch1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Got 32 and 64 in dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-779ce0d91641>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbatch2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mset3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Got 32 and 64 in dimension 2"
     ]
    }
   ],
   "source": [
    "batch2 = torch.cat([set3, set5], dim=1)\n",
    "print(batch2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above produces error due to unmatching sizes other than the dimension where concatenation is specified using the parameter 'dim'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 4 - Convert numpy array to tensor and vice versa\n",
    "\n",
    "In this section, the functions used to convert numpy arrays to a tensor as well as to convert a tensor to a numpy array are shown with examples. These are simple to use but very useful functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  3  5]\n",
      " [-2  1  2]\n",
      " [ 0  2  1]]\n",
      "<class 'numpy.ndarray'>\n",
      "tensor([[ 1,  3,  5],\n",
      "        [-2,  1,  2],\n",
      "        [ 0,  2,  1]])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Example 1 - Numpy array to a Tensor\n",
    "\n",
    "n1 = np.array([[1, 3, 5], [-2, 1, 2], [0, 2, 1]])\n",
    "print(n1)\n",
    "print(type(n1))\n",
    "\n",
    "n1_mod = torch.from_numpy(n1)\n",
    "print(n1_mod)\n",
    "print(type(n1_mod))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above example shows how a numpy array n1 is converted into a tensor using a torch function torch.from_numpy()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  3  5]\n",
      " [-2  1  2]\n",
      " [ 0  2  1]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Example 2 - from Tensor to numpy array\n",
    "\n",
    "n1_backto_array = n1_mod.numpy()\n",
    "print(n1_backto_array)\n",
    "print(type(n1_backto_array))\n",
    "\n",
    "assert(n1.all() == n1_backto_array.all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tensor created in the previous operation is converted back to the original form i.e. numpy array. Here we don't need any special function, instead the numpy() conversion function is available as an attribute of the torch tensor class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  3  5]\n",
      " [-2  1  2]\n",
      " [ 0  2  1]]\n",
      "[[ 1 -2  5]\n",
      " [-2  1  2]\n",
      " [ 0  2  1]]\n",
      "tensor([[ 1, -2,  5],\n",
      "        [-2,  1,  2],\n",
      "        [ 0,  2,  1]])\n"
     ]
    }
   ],
   "source": [
    "# Just a point to be noted: The numpy array and tensor share the same memory\n",
    "# Any changes in one reflect in the other too.\n",
    "\n",
    "print(n1) # original numpy array -- if we execute the cell twice, we wont see the difference\n",
    "n1[0,1] = -2\n",
    "print(n1)\n",
    "print(n1_mod) # tensor -- converted from numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1' '0']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.str_. The only supported types are: float64, float32, float16, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-c90deaed9544>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.str_. The only supported types are: float64, float32, float16, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking (to illustrate when it breaks)\n",
    "\n",
    "a = np.array(['1', '0'])\n",
    "print(a)\n",
    "b = torch.from_numpy(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a cooked example just to show the function torch.from_numpy() could fail. The reason for failure is obvious as the data is not in expected formats like int or float but is given in the string format. While the numpy module has its own processing functions to convert such data -- numbers presented as strings, torch doesn't allow them as raw string data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other than the above shown cooked example, the conversion functions torch.from_numpy() works all the time, and is often used to transfer between numpy and torch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 5 - working with gradients\n",
    "\n",
    "This section covers a few functions (from autograd module) that we need to compute gradients. The autograd module takes the flow of program code, and compute the gradients necessary for backward propagation, however each single iteration could be different depending on the flow/conditions of the code. The function .backward() on a tensor kickstarts the computation of derivatives and generates tracking history. If the tensor is a scalar, no arguments are necessary for .backward() function. If the tensor has more elements, a gradient argument is required. Finally, the gradient of the tensor is stored into .grad attribute. \n",
    "\n",
    "We can stop the tracking history using either .detach() to remove the tensor from computational graph, or by wrapping the code block in `with torch.no_grad():`The latter method finds its frequent use when evaluating a model having trainable parameters with `requires_grad=True` which triggers gradient computation when .backward() is called.\n",
    "\n",
    "One primary requirement for gradient computation of tensors is to set the tensor attribute i.e., requires_grad = True.\n",
    "\n",
    "`g1 = torch.tensor([1., 0.3])` --> here requires_grad=False by default. This means that there are no gradients to be computed for g1.\n",
    "\n",
    "`g2 = torch.tensor([1., 0.3], requires_grad=True)`\n",
    "\n",
    "We can change an existing value of the tensor's argument requires_grad using requires_grad_(value) where value can be True or False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "tensor([1.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "g1 = torch.tensor([1.])\n",
    "print(g1.requires_grad) # prints the default value when tensor is created\n",
    "\n",
    "g1.requires_grad_(True) # changes the value of argument in place\n",
    "\n",
    "print(g1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = g1 + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9.], grad_fn=<MulBackward0>)\n",
      "tensor([9.], grad_fn=<MulBackward0>) tensor(9., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Example 1 - evaluating gradients based on the definitions g1, y, and z.\n",
    "\n",
    "z = y * y\n",
    "print(z)\n",
    "out = z.mean()\n",
    "print(z, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6.])\n"
     ]
    }
   ],
   "source": [
    "# print out the gradients d(out)/dx\n",
    "print(g1.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above gradient evaluated by the tensor attribute .grad can be checked by manually computing the differential which is, (d[out]/dz) times (d[z]/dy) times (d[y]/dg1) = 1 * 2(3) * 1 = 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor([4.])\n"
     ]
    }
   ],
   "source": [
    "# Example 2 - Another simple function\n",
    "\n",
    "# g2 = 1, g3 = g2^2, out2 = 2 * g3\n",
    "\n",
    "# d(out2)/dg2 = (dout2/dg3) (dg3/dg2) = (2) (2 * g2) = (2) (2 * 1) = 4\n",
    "\n",
    "g2 = torch.tensor([1.], requires_grad=True)\n",
    "\n",
    "g3 = g2 * g2\n",
    "print(g3.requires_grad)\n",
    "out2 = g3 * 2\n",
    "out2.backward()\n",
    "print(g2.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Example 2 -- How to deactivate the gradient computation.\n",
    "# Either include the part inside a torch.no_grad() like below\n",
    "# Or use .detach() to get a new cloned tensor with no requires_grad\n",
    "g2 = torch.tensor([1.], requires_grad=True)\n",
    "g3 = g2 * g2\n",
    "\n",
    "print(g3.requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    g3 = g2 * g2\n",
    "    print(g3.requires_grad)\n",
    "g3.requires_grad_(True)\n",
    "print(g3.requires_grad)\n",
    "dummy = g3.detach()\n",
    "print(dummy.requires_grad)\n",
    "assert(g3==dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we set the g2 to have gradients. Then we define g3 as g2^2, and by default, g3 inherits the requires_grad, which is True, and hence the first print() gives True.\n",
    "\n",
    "Then we define the g3 definition inside `with torch.no_grad():`, and hence the requires_grad is set to False, thus the second print() gives False.\n",
    "\n",
    "We are explicitly setting the requires_grad attribute using requires_grad_(True) which is an inplace operation, and the following print() gives True for the requires_grad attribute.\n",
    "\n",
    "Finally, we use the .detach() to detach the requires_grad attribute and create a clone of g3 stored in dummy with requires_grad set to False, and hence the print() gives False.\n",
    "\n",
    "Other than requires_grad attribute both the dummy and g3 are same, and assert is used to confirm this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-b85886343ffb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mout2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mout2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch15/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch15/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking (to illustrate when it breaks)\n",
    "\n",
    "with torch.no_grad():\n",
    "    g2 = torch.tensor([1.], requires_grad=True)\n",
    "    g3 = g2 * g2\n",
    "    print(g3.requires_grad)\n",
    "    out2 = g3 * 2\n",
    "    out2.backward()\n",
    "    print(g2.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The definition of g3 is inside `with torch.no_grad():`, and hence requires_grad is set to False, the print() confirms this.\n",
    "\n",
    "Following operations, specifically out2.backward() doesn't work because there are no gradients to compute, and hence gives error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We discussed couple of functions that are used within autograd module. 1) First the attribute requires_grad of tensor should be set to True, to compute gradients of the tensor, 2) Example showed how partial derivatives are used to compute the gradient of the output w.r.t input, 3) The attribute .grad stores the gradients thus evaluated, 4) we can inactivate the gradient calculations by using .detach to separate the requires_grad attribute, or moving those parts of calculation that doesn't require gradients computation inside `with torch.no_grads():`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "There are a lot of functions to read and understand. I guess it is better to learn these functions and its usages along with the deep learning algorithms and domain applications. If we choose to learn the functions first and then apply in the deep learning applications, it may not work beneficially to us. So learn the deep learning algorithms / techniques such as CNNs, RNNs, DNNs, etc, and apply these tensor functions whereever required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Links\n",
    "Provide links to your references and other interesting articles about tensors\n",
    "* Official documentation for `torch.Tensor`: https://pytorch.org/docs/stable/tensors.html\n",
    "* https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html\n",
    "* https://medium.com/@Geeks_Today/five-magical-function-in-pytorch-956b3c7665a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jovian --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Attempting to save notebook..\u001b[0m\n",
      "[jovian] Updating notebook \"vgops75/01-tensor-operations\" on https://jovian.ml/\u001b[0m\n",
      "[jovian] Uploading notebook..\u001b[0m\n",
      "[jovian] Capturing environment..\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ml/vgops75/01-tensor-operations\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ml/vgops75/01-tensor-operations'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
